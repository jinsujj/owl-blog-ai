from kafka import KafkaConsumer, KafkaProducer
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration
import json
import time

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')
model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')

# Kafka ì„¤ì •
consumer = KafkaConsumer(
    "summary-request",
    bootstrap_servers="kafka:9092",
    auto_offset_reset="earliest",
    enable_auto_commit=True,
    group_id="summarizer",
    value_deserializer=lambda m: json.loads(m.decode("utf-8"))
)

producer = KafkaProducer(
    bootstrap_servers="kafka:9092",
    value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode("utf-8")
)

# Editor.js ë¸”ë¡ íŒŒì„œ
def parse_blocks(blocks):
    text_blocks = []

    for block in blocks:
        block_type = block.get("type")
        data = block.get("data", {})

        if block_type in ["paragraph", "header", "quote", "customHeader"]:
            text_blocks.append(str(data.get("text", "")))
        elif block_type in ["list", "checklist"]:
            for item in data.get("items", []):
                content = item.get("content") if isinstance(item, dict) else item
                text_blocks.append(str(content))
        elif block_type == "table":
            for row in data.get("content", []):
                row_text = " | ".join(row)
                text_blocks.append(row_text)

    return " ".join(text_blocks)

# ë¸”ë¡œê·¸ ìš”ì•½ ì²˜ë¦¬ ë£¨í”„
print("ğŸ“¥ Kafka consumer started! Waiting for blog-summarize-request...")

for message in consumer:
    try:
        blog_id = message.value.get("id")
        print(f"ğŸ” Received request for blogId: {blog_id}")

        # ë¸”ë¡œê·¸ API ìš”ì²­
        response = requests.get(f"https://backend.owl-dev.me/blogs/{blog_id}", timeout=10)
        response.raise_for_status()

        data = response.json()
        content_raw = data.get("content", "")
        content_dict = json.loads(content_raw)

        blocks = content_dict.get("blocks", [])
        full_text = parse_blocks(blocks).replace("\n", " ").strip()

        if not full_text:
            print(f"âš ï¸ Blog {blog_id} ë³¸ë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            continue

        start_time = time.time()
        input_ids = tokenizer.encode(full_text, return_tensors="pt", truncation=True, max_length=1024)
        summary_ids = model.generate(input_ids, num_beams=18, max_length=200, min_length=80)
        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
        elapsed_time = round(time.time() - start_time, 3)

        result = {
            "blogId": blog_id,
            "summary": summary,
            "elapsedTimeSec": elapsed_time
        }

        # ê²°ê³¼ ì „ì†¡
        producer.send("summary-response", result)
        print(f"âœ… Published summary for blogId {blog_id} in {elapsed_time} sec")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
